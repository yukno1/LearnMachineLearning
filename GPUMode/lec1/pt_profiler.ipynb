{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T15:20:10.948205Z",
     "start_time": "2025-08-03T15:20:05.811829Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "# ## Default way to use profiler\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "#     for _ in range(10):\n",
    "#         a = torch.square(torch.randn(10000, 10000).cuda())\n",
    "\n",
    "# prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "\n",
    "## With warmup and skip\n",
    "# https://pytorch.org/docs/stable/profiler.html\n",
    "\n",
    "# Non-default profiler schedule allows user to turn profiler on and off\n",
    "# on different iterations of the training loop;\n",
    "# trace_handler is called every time a new trace becomes available\n",
    "def trace_handler(prof):\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "    prof.export_chrome_trace(\"test_trace_\" + str(prof.step_num) + \".json\")\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "\n",
    "    # In this example with wait=1, warmup=1, active=2, repeat=1,\n",
    "    # profiler will skip the first step/iteration,\n",
    "    # start warming up on the second, record\n",
    "    # the third and the forth iterations,\n",
    "    # after which the trace will become available\n",
    "    # and on_trace_ready (when set) is called;\n",
    "    # the cycle repeats starting with the next step\n",
    "\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=2,\n",
    "        repeat=1),\n",
    "    on_trace_ready=trace_handler\n",
    "    # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n",
    "    # used when outputting for tensorboard\n",
    "    ) as p:\n",
    "        for iter in range(10):\n",
    "            torch.square(torch.randn(10000, 10000).cuda())\n",
    "            # send a signal to the profiler that the next iteration has started\n",
    "            p.step()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "            ProfilerStep*         2.87%      26.973ms        99.74%     936.619ms     468.309ms             2  \n",
      "              aten::randn         0.01%      57.900us        88.47%     830.750ms     415.375ms             2  \n",
      "              aten::empty         0.04%     363.500us         0.04%     363.500us     181.750us             2  \n",
      "            aten::normal_        88.42%     830.329ms        88.42%     830.329ms     415.164ms             2  \n",
      "                 aten::to         0.00%      39.500us         8.38%      78.646ms      19.662ms             4  \n",
      "           aten::_to_copy         0.00%      37.500us         8.37%      78.607ms      39.303ms             2  \n",
      "      aten::empty_strided         0.00%      46.500us         0.00%      46.500us      23.250us             2  \n",
      "              aten::copy_         0.01%      60.600us         8.36%      78.523ms      39.261ms             2  \n",
      "          cudaMemcpyAsync         8.34%      78.327ms         8.34%      78.327ms      39.164ms             2  \n",
      "    cudaStreamSynchronize         0.01%     135.100us         0.01%     135.100us      67.550us             2  \n",
      "             aten::square         0.00%      10.700us         0.03%     251.400us     125.700us             2  \n",
      "                aten::pow         0.01%     133.000us         0.03%     240.700us     120.350us             2  \n",
      "        aten::result_type         0.00%       2.000us         0.00%       2.000us       1.000us             2  \n",
      "         cudaLaunchKernel         0.01%     104.100us         0.01%     104.100us      52.050us             2  \n",
      "    cudaDeviceSynchronize         0.26%       2.420ms         0.26%       2.420ms       2.420ms             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 939.039ms\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fb81d5a85846d78e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
